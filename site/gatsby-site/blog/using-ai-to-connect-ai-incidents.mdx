---
title: Using AI to Connect AI Incidents
metaTitle: Using AI to Connect AI Incidents
metaDescription: ''
date: 2022-06-29
image: ../src/images/facet.png
author: Nicholas Broce, Nicholas Olson, and Jason Scott-Hakanson.

---

<!-- TODO: Add something at the top about this being a guest post -->

> This is a guest post written by three members of an Oregon State University (OSU) Capstone team, including Nicholas Broce, [Nicholas Olson](https://www.linkedin.com/in/olson-nick), and [Jason Scott-Hakanson](https://www.linkedin.com/in/jason-scott-hakanson-953556221).[^1]

The AI Incident Database (AIID) [launched](https://partnershiponai.org/aiincidentdatabase) publicly in November 2020 as a dashboard of AI harms realized in the real world. Inspired by similar databases in the aviation industry, its change thesis is derived from the Santayana aphorism, “Those who cannot remember the past are condemned to repeat it.” This newest addition to the AIID toolset aims to make it easier to connect, categorize, and correlate the emerging history of AI and to monitor unfolding events to find where past lessons have been repeated.

## The Newest Tool in the Box

Over the course of the 2021–22 academic year, four students at OSU were tasked with creating a tool that can answer the question, “what are the most similar incidents to this document?”

The students are proud to showcase the result of their work. The main outcome is an <abbr title="Application Programming Interface">API</abbr> that takes an arbitrary input text, like a news report or press release, and outputs the IDs of the most similar incidents in the database. Each incident in the database is a collection of news reports about the same event, and each of these clusters is given a unique “incident ID”, allowing any text to be compared to a clustered understanding of the reports rather than a text-to-text comparison using keywords.

<!-- TODO: Insert GIF/video showing it working -->

The API is currently being used by AIID contributers to identify new submissions reporting on incidents already in the database. It is also planned to be fitted for future use-cases, including:

- graphically visualizing relations between incidents in the AIID
- automatically identifying news reports to be added to the database

<!-- Are these worth mentioning? -->
<!--
- A web plugin to run on any website and generate a list of similar articles about the current website you are viewing
- A Twitter bot that waits for tweets that link to new articles by major news networks, and replies with possibly similar AI Incidents in the AIID
-->

In testing, the Longformer model was about 94% accurate at correlating leave-one-out reports in the database back to their own incident IDs. The model is especially accurate with news reports or similarly long input texts, and less so with shorter input texts that less closely resemble existing incidents. We hope to tackle both of these issues in future iterations.

The project is [fully open source](https://github.com/responsible-ai-collaborative/nlp-lambdas) and is built to be modular, extensible, and easily changed for future development. New models, new techniques, and new features can and will be easily added to this API to fulfill future needs.

If you want to know more about how this project was built, how it works, its current limitations, and how you can contribute, see our appendix <!-- TODO: Figure out where to put the technical content, update this sentence accordingly --> on the technical details!

## Try it Yourself!

You can find the first integration of this tool available at the link below, and we encourage you to play around with it and explore the articles you find. One the website scroll down to the field labeled text and that is the input field for our API. After a short calculation time, articles should begin to appear at the bottom of the page.

<!-- TODO: Add appropriate link -->

[^1]: Having completed their capstone, the authors will all be starting Software Engineering internships this July, with Nicholas Broce at **PCC Structurals Inc**, Nicholas Olson at **Cognex**, and Jason Scott-Hakanson at **Lam Research**.

